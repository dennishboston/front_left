{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta, date, datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-086316521d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#transit_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mairport_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mairport_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#transit_df\n",
    "airport_data = pd.read_csv(\"data.csv\")\n",
    "airport_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_data[\"FLIGHTS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import airline names and convert to dict\n",
    "\n",
    "carrier_names = pd.read_csv(\"L_UNIQUE_CARRIERS.csv\")\n",
    "\n",
    "carrier_names = carrier_names.rename(columns={\"Description\":\"Airline\", \"Code\":\"CARRIER\"})\n",
    "\n",
    "abbr_carrier = carrier_names.set_index(\"CARRIER\")[\"Airline\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find top ten arirports\n",
    "\n",
    "top_ten_dest = airport_data[\"FLIGHTS\"].groupby(airport_data[\"DEST\"]).sum().reset_index()\n",
    "top_ten_dest = top_ten_dest.sort_values(by=\"FLIGHTS\", ascending=False)\n",
    "top_ten_dest = top_ten_dest.head(10)\n",
    "\n",
    "top_ten_orig = airport_data[\"FLIGHTS\"].groupby(airport_data[\"ORIGIN\"]).sum().reset_index()\n",
    "top_ten_orig = top_ten_orig.sort_values(by=\"FLIGHTS\", ascending=False)\n",
    "top_ten_orig = top_ten_orig.head(10)\n",
    "\n",
    "top_ten_orig.to_csv(\"Top Ten Origins\")\n",
    "top_ten_dest.to_csv(\"Top Ten Destinations\")\n",
    "top_ten_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delays by airline\n",
    "airline_delays = airport_data.loc[:,[\"CARRIER\", \"Total_Delay\", \"DEP_DELAY\", \"ARR_DELAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic descriptive stats for airlines\n",
    "\n",
    "def get_stats(group):\n",
    "    return {\"Min Delay\" : group.min(), \"Max Delay\" : group.max(), \"Number Flight Delays\" : group.count(),\n",
    "            \"Mean Departure Delay\" : group.mean()}\n",
    "\n",
    "stat_overview = airport_data\n",
    "stat_overview[\"CARRIER\"] = stat_overview[\"CARRIER\"].replace(abbr_carrier)\n",
    "stat_overview = airport_data[\"DEP_DELAY\"].groupby(airport_data[\"CARRIER\"]).apply(get_stats).unstack()\n",
    "stat_overview = stat_overview.sort_values(\"Number Flight Delays\")\n",
    "stat_overview = stat_overview[[\"Max Delay\", \"Min Delay\", \"Mean Departure Delay\", \"Number Flight Delays\"]]\n",
    "stat_overview = stat_overview.sort_values(\"Mean Departure Delay\")\n",
    "stat_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of flights for \"worst\" airline by departure airport\n",
    "\n",
    "jet_blue = airport_data.loc[airport_data[\"CARRIER\"] == \"JetBlue Airways\"]\n",
    "jb_orig = pd.DataFrame(jet_blue.groupby(\"ORIGIN\").FLIGHTS.count())\n",
    "jb_orig = jb_orig.sort_values(\"FLIGHTS\", ascending=False)\n",
    "jb_orig.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of flights for \"best\" airline by departure airport\n",
    "\n",
    "ha = airport_data.loc[airport_data[\"CARRIER\"] == \"Hawaiian Airlines Inc.\"]\n",
    "ha_orig = pd.DataFrame(ha.groupby(\"ORIGIN\").FLIGHTS.count())\n",
    "ha_orig = ha_orig.sort_values(\"FLIGHTS\", ascending=False)\n",
    "ha_orig.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get df with only top ten airports as origin\n",
    "top_ten = airport_data[airport_data[\"ORIGIN\"].isin(top_ten_orig[\"ORIGIN\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calc mean dep delay and sd by origin\n",
    "top_ten_stats = []\n",
    "airline_stats = []\n",
    "\n",
    "for origin in top_ten[\"ORIGIN\"].unique():\n",
    "    airport_stats = {}\n",
    "    temp = top_ten.loc[top_ten[\"ORIGIN\"] == origin]\n",
    "    airport_stats[\"Airport\"] = origin\n",
    "    airport_stats[\"Mean\"] = temp[\"DEP_DELAY\"].mean()\n",
    "    airport_stats[\"STD\"] = np.std(temp[\"DEP_DELAY\"])\n",
    "    top_ten_stats.append(airport_stats)\n",
    "\n",
    "    #calc stats for each airline\n",
    "    for carrier in airport_data[\"CARRIER\"].unique():\n",
    "        carrier_stats = {}\n",
    "        temp2 = temp.loc[temp[\"CARRIER\"] == carrier]\n",
    "        carrier_stats[\"Airline\"] = carrier\n",
    "        carrier_stats[\"Airport\"] = origin\n",
    "        carrier_stats[\"zscore\"] = (temp2[\"DEP_DELAY\"].mean() - temp[\"DEP_DELAY\"].mean()) / np.std(temp[\"DEP_DELAY\"])\n",
    "        airline_stats.append(carrier_stats)\n",
    "        \n",
    "top_ten_stats = pd.DataFrame(top_ten_stats)\n",
    "airline_stats = pd.DataFrame(airline_stats)\n",
    "airline_stats = airline_stats.fillna(0)\n",
    "#airline_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean zscore for each ailrine grouped by airoprt and sorted\n",
    "\n",
    "airline_comparison = airline_stats.groupby(\"Airline\").mean()\n",
    "airline_comparison = airline_comparison.sort_values(\"zscore\")\n",
    "airline_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc avg z score by airline\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "x_axis = np.arange(0,len(airline_comparison.index))\n",
    "tick_locations = []\n",
    "for x in x_axis:\n",
    "    tick_locations.append(x)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Airline Relative Performance at Busiest Airports\", fontsize=18, bbox={\"facecolor\":\"midnightblue\", \"pad\":5}, color='w', labelpad=20)\n",
    "plt.ylabel(\"Mean Z-Score\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.bar(x_axis, airline_comparison[\"zscore\"], facecolor=\"firebrick\", alpha=0.75, align=\"edge\",)\n",
    "plt.xticks(tick_locations, airline_comparison.index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df with airlines and delays and replace code with airline name\n",
    "airline_delays[\"CARRIER\"] = airline_delays[\"CARRIER\"].replace(abbr_carrier)\n",
    "\n",
    "fig = plt.figure(1, figsize=(16,15))\n",
    "gs=GridSpec(2,2)\n",
    "ax=fig.add_subplot(gs[0,:])\n",
    "\n",
    "colors = ['firebrick', 'gold', 'lightcoral', 'aquamarine', 'yellowgreen', \n",
    "          'seagreen', 'tomato', 'violet', 'wheat', 'chartreuse', 'lightskyblue', 'royalblue']\n",
    "\n",
    "ax = sns.stripplot(y=\"CARRIER\", x=\"DEP_DELAY\", size=6, palette=colors, data=airline_delays, linewidth=.5, jitter=True)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(['{:2.0f}h{:2.0f}m'.format(*[int(y) for y in divmod(x,60)])\n",
    "                         for x in ax.get_xticks()])\n",
    "ax.yaxis.label.set_visible(False)\n",
    "plt.xlabel(\"Departure Delay in Minutes by Airline\", fontsize=18, bbox={\"facecolor\":\"midnightblue\", \"pad\":5}, color='w', labelpad=20)\n",
    "#plt.figure(figsize=(20,10))\n",
    "plt.savefig('delay_in_min_by_airline.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DENNIS' CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"deep\", desat=.6)\n",
    "colors = sns.color_palette(\"deep\")\n",
    "sns.set_context(rc={\"figure.figsize\": (50, 20)})\n",
    "pd.set_option('display.max_columns', 500)\n",
    "transit_csv= \"data.csv\"\n",
    "transit_df = pd.read_csv(transit_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_df.fillna(0, inplace=True)\n",
    "transit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancels = transit_df.groupby('FL_DATE').CANCELLED.sum()\n",
    "flights = transit_df.groupby('FL_DATE').FL_DATE.count()\n",
    "aFlight = (transit_df.groupby('FL_DATE').FL_DATE.count() - transit_df.groupby('FL_DATE').CANCELLED.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = transit_df.groupby('FL_DATE').WEATHER_DELAY.sum()\n",
    "carrier = transit_df.groupby('FL_DATE').CARRIER_DELAY.sum()\n",
    "nas = transit_df.groupby('FL_DATE').NAS_DELAY.sum()\n",
    "security = transit_df.groupby('FL_DATE').SECURITY_DELAY.sum()\n",
    "lateAircraft = transit_df.groupby('FL_DATE').LATE_AIRCRAFT_DELAY.sum()\n",
    "delays = weather + carrier + nas + security + lateAircraft\n",
    "destinations = transit_df[\"DEST_CITY_NAME\"].unique()\n",
    "len(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = np.arange(1, 30, 1)\n",
    "# dte = cancelledByDate\n",
    "dte = (\"1\", \"2\",\"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\",\n",
    "       \"11\", \"12\",\"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\",\n",
    "       \"21\", \"22\",\"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(len(dte))#how many things to plot\n",
    "# plt.plot(<X AXIS VALUES HERE>, <Y AXIS VALUES HERE>, 'line type', label='label here')\n",
    "# plt.plot(<X AXIS VALUES HERE>, <Y AXIS VALUES HERE>, 'line type', label='label here')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(index, cancels, 'r-', label=\"Cancelled Flights\")\n",
    "#plt.plot(index, flights, 'b-', label=\"Attempted Flights\")\n",
    "plt.plot(index, aFlight, 'y-', label=\"Flown Flights\")\n",
    "#plt.plot(index, delays, 'y-', label=\"Delays\")\n",
    "plt.xticks(index, dte, fontsize=15)\n",
    "plt.title('Flights by (date)', fontsize=15)\n",
    "plt.xlabel('September 2017', fontsize=15)\n",
    "plt.ylabel('Flights', fontsize=15)\n",
    "plt.axvspan(8,13,color='y',alpha=0.5, label=\"Irma\")\n",
    "plt.axvspan(18,20,color='orange',alpha=0.5, label=\"Maria\")\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(len(dte))#how many things to plot\n",
    "# plt.plot(<X AXIS VALUES HERE>, <Y AXIS VALUES HERE>, 'line type', label='label here')\n",
    "# plt.plot(<X AXIS VALUES HERE>, <Y AXIS VALUES HERE>, 'line type', label='label here')\n",
    "# plt.plot(index, delays, 'r-', label=\"Tot Delays\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(index, carrier, '-', label=\"Carrier\")\n",
    "plt.plot(index, weather, '-', label=\"Weather\")\n",
    "plt.plot(index, nas, '-', label=\"NAS\")\n",
    "plt.plot(index, security, '-', label=\"Security\")\n",
    "plt.plot(index, lateAircraft, '-', label=\"Late Aircraft\")\n",
    "plt.xticks(index, dte, fontsize=15)\n",
    "plt.xlabel('September 2017', fontsize=15)\n",
    "plt.title('Delays by (date)', fontsize=15)\n",
    "plt.ylabel('Delays (Minutes)', fontsize=15)\n",
    "plt.axvspan(8,13,color='y',alpha=0.5, label=\"Irma\")\n",
    "plt.axvspan(18,20,color='orange',alpha=0.5, label=\"Maria\")\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's group by state now and sum the number of delays.\n",
    "by_origin_state = transit_df.groupby('ORIGIN_STATE_ABR')\n",
    "departure_delay_counts = by_origin_state.DEP_DEL15.sum()\n",
    "cancel_delay_counts = by_origin_state.CANCELLED.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_dest_state = transit_df.groupby('DEST_STATE_ABR')\n",
    "arrival_delay_counts = by_dest_state.ARR_DEL15.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot, we'll put both series in a DataFrame so we can view the arrival and departure delays for each state\n",
    "delay_df = pd.DataFrame([departure_delay_counts, arrival_delay_counts, cancel_delay_counts]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df.sort_values('DEP_DEL15', ascending=False).plot(kind='bar', title='Number of delayed flights by state', figsize=(20,10))\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali = transit_df.loc[(transit_df[\"ORIGIN_STATE_ABR\"] == \"CA\")]\n",
    "cali= cali.reset_index()\n",
    "cdelay = cali.groupby([\"ORIGIN\"]).sum()\n",
    "cdelay = cdelay[\"DEP_DELAY\"]\n",
    "ccancelled = cali.groupby([\"ORIGIN\"]).sum()\n",
    "ccancelled = ccancelled[\"CANCELLED\"]\n",
    "cdate_delay_count = cali.groupby('FL_DATE')\n",
    "ca_aFlight = (cali.groupby('FL_DATE').FL_DATE.count() - cali.groupby('FL_DATE').CANCELLED.sum())\n",
    "cdate_cancels = cali.groupby('FL_DATE').CANCELLED.sum()\n",
    "cdate_delay_count = cali.loc[(cali[\"DEP_DEL15\"] > 0)]\n",
    "cdate_delay_count = cdate_delay_count.groupby('FL_DATE').DEP_DEL15.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pandas.io.html import read_html\n",
    "# wiki_fires = pd.read_html(\"https://en.wikipedia.org/wiki/2017_California_wildfires\")\n",
    "# wildfire_df = wiki_fires[1]\n",
    "# wildfire_df\n",
    "# wildfire_df.columns = wildfire_df.iloc[0]\n",
    "# wildfire_df = wildfire_df[1:]\n",
    "# wildfire_df = wildfire_df.drop([\"Notes\"],axis=1)\n",
    "# wildfire_df[\"Acres\"] = wildfire_df[\"Acres\"].astype(\"int64\")\n",
    "# wildfire_df = wildfire_df.sort_values(\"Acres\",ascending=False)\n",
    "# wildfire_df = wildfire_df.reset_index()\n",
    "\n",
    "wildfire_sept = pd.read_csv(\"wildfires.csv\")\n",
    "wildfire_sept.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "airports = [\"ACV\", \"BFL\", \"BUR\", \"FAT\", \"LAX\", \"LGB\",\"MRY\", \"OAK\", \"ONT\", \"PSP\" ,\"RDD\" ,\"SAN\", \"SBA\", \"SBP\", \"SFO\", \"SJC\" ,\"SMF\", \"SNA\", \"STS\"]\n",
    "x_axis = np.arange(len(cdelay))\n",
    "barlist = plt.bar(x_axis,cdelay,color=\"forestgreen\",align=\"edge\")\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, airports, fontsize=15)\n",
    "plt.xlim(-0.25, len(x_axis))\n",
    "plt.ylim(0, max(cdelay))\n",
    "plt.title(\"Airline Departure Delays in California During the Month of September 2017\", fontsize=15)\n",
    "plt.xlabel(\"Airport\", fontsize=15)\n",
    "plt.ylabel(\"Time of Delay (minutes)\", fontsize=15)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "airports = [\"ACV\", \"BFL\", \"BUR\", \"FAT\", \"LAX\", \"LGB\",\"MRY\", \"OAK\", \"ONT\", \"PSP\" ,\"RDD\" ,\"SAN\", \"SBA\", \"SBP\", \"SFO\", \"SJC\" ,\"SMF\", \"SNA\", \"STS\"]\n",
    "x_axis = np.arange(len(ccancelled))\n",
    "barlist = plt.bar(x_axis,ccancelled,color=\"crimson\",align=\"edge\")\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, airports, fontsize=15)\n",
    "plt.xlim(-0.25, len(x_axis))\n",
    "plt.ylim(0, max(ccancelled))\n",
    "plt.title(\"Airline Cancellations in California During the Month of September 2017\", fontsize=15)\n",
    "plt.xlabel(\"Airport\", fontsize=15)\n",
    "plt.ylabel(\"Number of Cancellations\", fontsize=15)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(len(dte))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(index, cdate_delay_count, 'r-', label=\"Delayed Flights\")\n",
    "plt.plot(index, cdate_cancels, \"blue\", label=\"Cancelled Flights\")\n",
    "plt.plot(index, ca_aFlight, 'black', label=\"Flown Flights\")\n",
    "plt.xticks(index, dte, fontsize=15)\n",
    "plt.title('California Flights by (date)', fontsize=15)\n",
    "plt.xlabel('September 2017', fontsize=15)\n",
    "plt.axvspan(13,23,color='forestgreen',alpha=0.5, label=\"10 wildfires burning on this date\")\n",
    "plt.axvspan(26,29,color='blue',alpha=0.5, label=\"11 wildfires burning on this date\")\n",
    "plt.axvspan(9,11,color='blue',alpha=0.5)\n",
    "plt.axvspan(12,13,color='blue',alpha=0.5)\n",
    "plt.axvspan(23,24,color='blue',alpha=0.5)\n",
    "plt.axvspan(11,12,color='yellow',alpha=0.5, label=\"12 wildfires burning on this date\")\n",
    "plt.axvspan(24,26, color='yellow',alpha=0.5,)\n",
    "plt.axvspan(0,2,color='orange',alpha=0.5, label=\"13 wildfires burning on this date\")\n",
    "plt.axvspan(6,9,color='orange',alpha=0.5)\n",
    "plt.axvspan(2,6,color='red',alpha=0.5, label=\"14 wildfires burning on this date\")\n",
    "plt.ylabel('Flights', fontsize=15)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to return conditions\n",
    "def get_conditions(readDate):\n",
    "    api_conditions_url = \"http://api.wunderground.com/api/\" + WUNDERGROUND_API_KEY + \"/history_\" + readDate + \"/q/\" + STATE +\"/\"+ CITY + \".json\"\n",
    "    try:\n",
    "        f = requests.get(api_conditions_url).json()\n",
    "        print(api_conditions_url)\n",
    "    except:\n",
    "        print(\"Failed to get conditions\")\n",
    "        return False\n",
    "    if CITY == \"SCE\":\n",
    "        return False\n",
    "    else:\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv again\n",
    "csv_path = \"data.csv\"\n",
    "weather_df = pd.read_csv(csv_path, low_memory=False)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE CHART WITH WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_delays_df = weather_df.loc[((weather_df[\"WEATHER_DELAY\"] > 0)) & ((weather_df[\"ORIGIN\"]==\"PHL\") | (weather_df[\"ORIGIN\"]==\"DFW\") | (weather_df[\"ORIGIN\"]==\"BOS\") | (weather_df[\"ORIGIN\"]==\"JFK\") | (weather_df[\"ORIGIN\"]==\"IAH\") | (weather_df[\"ORIGIN\"]==\"DEN\") | (weather_df[\"ORIGIN\"]==\"LGA\") | (weather_df[\"ORIGIN\"]==\"ORD\") | (weather_df[\"ORIGIN\"]==\"EWR\") | (weather_df[\"ORIGIN\"]==\"SFO\") | (weather_df[\"DEST\"]==\"PHL\") | (weather_df[\"DEST\"]==\"DFW\") | (weather_df[\"DEST\"]==\"BOS\") | (weather_df[\"DEST\"]==\"JFK\") | (weather_df[\"DEST\"]==\"IAH\") | (weather_df[\"DEST\"]==\"DEN\") | (weather_df[\"DEST\"]==\"LGA\") | (weather_df[\"DEST\"]==\"ORD\") | (weather_df[\"DEST\"]==\"EWR\") | (weather_df[\"DEST\"]==\"SFO\")) & (weather_df[\"DEST\"]!=\"OMA\") & (weather_df[\"ORIGIN\"]!=\"OMA\"),:]\n",
    "weather_delays_df.reset_index(inplace=True)\n",
    "weather_delays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_map_df = pd.DataFrame(weather_delays_df.loc[:,[\"YEAR\", \"MONTH\", \"DAY_OF_MONTH\", \"DAY_OF_WEEK\",\n",
    "                                          \"FL_DATE\",\"CARRIER\",\"ORIGIN\",\"ORIGIN_STATE_ABR\",\"DEST\",\"DEST_STATE_ABR\",\"DEP_TIME\",\"CRS_ARR_TIME\",\"WEATHER_DELAY\",\"CANCELLATION_CODE\"]])\n",
    "weather_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create columns for weather conditions to be pulled\n",
    "weather_map_df[\"Conds_Description\"] = \"conds\"\n",
    "weather_map_df[\"Visibility\"] = 0.0\n",
    "weather_map_df[\"Pressure\"] = 0.0\n",
    "weather_map_df[\"Precipitation\"] = 0.0\n",
    "weather_map_df[\"Wind\"] = 0.0\n",
    "weather_map_df[\"Wind_Gust\"] = 0.0 \n",
    "weather_map_df[\"Fog\"] = 0.0\n",
    "weather_map_df[\"Snow\"] = 0.0\n",
    "weather_map_df[\"Temp\"] = 0.0\n",
    "weather_map_df[\"Thunder\"] = 0.0\n",
    "weather_map_df[\"Tornado\"] = 0.0\n",
    "weather_map_df[\"Rain\"] = 0.0\n",
    "weather_map_df[\"Hail\"] = 0.0\n",
    "\n",
    "weather_map_df[\"Dest_Conds_Description\"] = \"conds\"\n",
    "weather_map_df[\"Dest_Visibility\"] = 0.0\n",
    "weather_map_df[\"Dest_Pressure\"] = 0.0\n",
    "weather_map_df[\"Dest_Precipitation\"] = 0.0\n",
    "weather_map_df[\"Dest_Wind\"] = 0.0\n",
    "weather_map_df[\"Dest_Wind_Gust\"] = 0.0 \n",
    "weather_map_df[\"Dest_Fog\"] = 0.0\n",
    "weather_map_df[\"Dest_Snow\"] = 0.0\n",
    "weather_map_df[\"Dest_Temp\"] = 0.0\n",
    "weather_map_df[\"Dest_Thunder\"] = 0.0\n",
    "weather_map_df[\"Dest_Tornado\"] = 0.0\n",
    "weather_map_df[\"Dest_Rain\"] = 0.0\n",
    "weather_map_df[\"Dest_Hail\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wunderground keys\n",
    "STARTDATE2 = \"\"\n",
    "WUNDERGROUND_API_KEY = \"aa2877982956f024\"\n",
    "BUCKET_KEY = \"wu1\"\n",
    "ACCESS_KEY = \"aa2877982956f024\"\n",
    "\n",
    "#loop through weather delays\n",
    "weather_delays_count = len(weather_map_df)\n",
    "for row in range(weather_delays_count-1):\n",
    "    STATE = weather_map_df.iloc[row][\"ORIGIN_STATE_ABR\"]\n",
    "    CITY = weather_map_df.iloc[row][\"ORIGIN\"]\n",
    "    row_year = int(weather_map_df.iloc[row][\"YEAR\"])\n",
    "    row_month = int(weather_map_df.iloc[row][\"MONTH\"])\n",
    "    row_day = int(weather_map_df.iloc[row][\"DAY_OF_MONTH\"])\n",
    "    \n",
    "    STARTDATE2 = date(row_year,row_month,row_day)\n",
    "    \n",
    "    date_wu = []\n",
    "    humidity_wu = []\n",
    "    temp_wu = []\n",
    "    pressure_wu = []\n",
    "    precip_wu = []\n",
    "    wind_speed_wu = []\n",
    "    dewpt_wu = []\n",
    "    wind_gust_wu = []\n",
    "    wind_dir_wu = []\n",
    "    vis_wu = []\n",
    "    wind_chill_wu = []\n",
    "    heat_index_wu = []\n",
    "    conds_wu = []\n",
    "    fog_wu = []\n",
    "    rain_wu = []\n",
    "    snow_wu = []\n",
    "    hail_wu = []\n",
    "    thunder_wu = []\n",
    "    tornado_wu = []\n",
    "    \n",
    "    dest_date_wu = []\n",
    "    dest_humidity_wu = []\n",
    "    dest_temp_wu = []\n",
    "    dest_pressure_wu = []\n",
    "    dest_precip_wu = []\n",
    "    dest_wind_speed_wu = []\n",
    "    dest_dewpt_wu = []\n",
    "    dest_wind_gust_wu = []\n",
    "    dest_wind_dir_wu = []\n",
    "    dest_vis_wu = []\n",
    "    dest_wind_chill_wu = []\n",
    "    dest_heat_index_wu = []\n",
    "    dest_conds_wu = []\n",
    "    dest_fog_wu = []\n",
    "    dest_rain_wu = []\n",
    "    dest_snow_wu = []\n",
    "    dest_hail_wu = []\n",
    "    dest_thunder_wu = []\n",
    "    dest_tornado_wu = []\n",
    "\n",
    "    #pull conditions for origin city on day of flight\n",
    "    conditions = get_conditions(STARTDATE2.strftime(\"%Y%m%d\"))\n",
    "\n",
    "    if (conditions != False):\n",
    "        for i in range(len(conditions['history']['observations'])):\n",
    "            dateInfo = conditions['history']['observations'][i]['date']\n",
    "            date_holder = dateInfo['mon']+\"/\"+dateInfo['mday']+\"/\"+dateInfo['year']+\" \"+dateInfo['hour']+dateInfo['min']\n",
    "            pattern = '%m/%d/%Y %H%M'\n",
    "            date_wu.append(date_holder)\n",
    "            epoch = int(time.mktime(time.strptime(date_holder, pattern)))\n",
    "\n",
    "            humidity_wu.append(conditions['history']['observations'][i]['hum'])\n",
    "            temp_wu.append(conditions['history']['observations'][i]['tempi'])\n",
    "            pressure_wu.append(conditions['history']['observations'][i]['pressurei'])\n",
    "            precip_wu.append(conditions['history']['observations'][i]['precipi'])\n",
    "            wind_speed_wu.append(conditions['history']['observations'][i]['wspdi'])\n",
    "            dewpt_wu.append(conditions['history']['observations'][i]['dewpti'])\n",
    "            wind_gust_wu.append(conditions['history']['observations'][i]['wgusti'])\n",
    "            wind_dir_wu.append(conditions['history']['observations'][i]['wdird'])\n",
    "            vis_wu.append(conditions['history']['observations'][i]['visi'])\n",
    "            wind_chill_wu.append(conditions['history']['observations'][i]['windchilli'])\n",
    "            heat_index_wu.append(conditions['history']['observations'][i]['heatindexi'])\n",
    "            conds_wu.append(conditions['history']['observations'][i]['conds'])\n",
    "            fog_wu.append(conditions['history']['observations'][i]['fog'])\n",
    "            rain_wu.append(conditions['history']['observations'][i]['rain'])\n",
    "            snow_wu.append(conditions['history']['observations'][i]['snow'])\n",
    "            hail_wu.append(conditions['history']['observations'][i]['hail'])\n",
    "            thunder_wu.append(conditions['history']['observations'][i]['thunder'])\n",
    "            tornado_wu.append(conditions['history']['observations'][i]['tornado'])\n",
    "\n",
    "        obs_df = pd.DataFrame({\n",
    "            \"Date\":date_wu,\n",
    "            \"Temp\":temp_wu,\n",
    "            \"Pressure\":pressure_wu,\n",
    "            \"Precipitation\":precip_wu,\n",
    "            \"Wind_Gust\":wind_gust_wu,\n",
    "            \"Wind\":wind_speed_wu,\n",
    "            \"Visibility\":vis_wu,\n",
    "            \"Conds_Description\":conds_wu,\n",
    "            \"Fog\":fog_wu,\n",
    "            \"Rain\":rain_wu,\n",
    "            \"Snow\":snow_wu,\n",
    "            \"Hail\":hail_wu,\n",
    "            \"Thunder\":thunder_wu,\n",
    "            \"Tornado\":tornado_wu\n",
    "        })\n",
    "\n",
    "        #find the closest observation to the scheduled flight time\n",
    "        military_time = int(weather_map_df.iloc[row][\"DEP_TIME\"])\n",
    "        if military_time < 1000:\n",
    "            time_str = \"0\" + str(military_time)\n",
    "        else:\n",
    "            time_str = str(military_time)\n",
    "\n",
    "        rcd_time = str(row_month) + \"/\" + str(row_day) + \"/\" + str(row_year) + \" \" + str(time_str)\n",
    "        rec_time = datetime.strptime(rcd_time, '%m/%d/%Y %H%M')\n",
    "\n",
    "        closest_time = rec_time\n",
    "        min_diff = 99999999999\n",
    "\n",
    "        converted_timestamps = []\n",
    "        for raw_time in date_wu:\n",
    "            converted_time = datetime.strptime(raw_time, '%m/%d/%Y %H%M')\n",
    "            converted_timestamps.append(converted_time)\n",
    "            diff = rec_time - converted_time\n",
    "            if diff.seconds < min_diff:\n",
    "                min_diff = diff.seconds\n",
    "                closest_time = converted_time\n",
    "\n",
    "        closest = closest_time.strftime(\"%m/%d/%Y %H%M\")        \n",
    "\n",
    "        #add conditions closest to departure time to main data frame\n",
    "        observation = obs_df.loc[obs_df[\"Date\"]==closest,:]\n",
    "        observation_fog = observation[\"Fog\"]\n",
    "        observation_pressure = observation[\"Pressure\"]\n",
    "        observation_snow = observation[\"Snow\"]\n",
    "        observation_temp = observation[\"Temp\"]\n",
    "        observation_thunder = observation[\"Thunder\"]\n",
    "        observation_wind = observation[\"Wind\"]\n",
    "        observation_wind_gust = observation[\"Wind_Gust\"]\n",
    "        observation_rain = observation[\"Rain\"]\n",
    "        observation_tornado = observation[\"Tornado\"]\n",
    "        observation_visibility = observation[\"Visibility\"]\n",
    "        observation_conds_description = observation[\"Conds_Description\"]\n",
    "        observation_precipitation = observation[\"Precipitation\"]\n",
    "        observation_hail = observation[\"Hail\"]\n",
    "\n",
    "        weather_map_df.loc[row,\"Fog\"] = float(observation_fog)\n",
    "        weather_map_df.loc[row,\"Pressure\"] = float(observation_pressure)\n",
    "        weather_map_df.loc[row,\"Snow\"] = float(observation_snow)\n",
    "        weather_map_df.loc[row,\"Temp\"] = float(observation_temp)\n",
    "        weather_map_df.loc[row,\"Thunder\"] = float(observation_thunder)\n",
    "        weather_map_df.loc[row,\"Wind\"] = float(observation_wind)\n",
    "        weather_map_df.loc[row,\"Wind_Gust\"] = float(observation_wind_gust)\n",
    "        weather_map_df.loc[row,\"Rain\"] = float(observation_rain)\n",
    "        weather_map_df.loc[row,\"Tornado\"] = float(observation_tornado)\n",
    "        weather_map_df.loc[row,\"Visibility\"] = float(observation_visibility)\n",
    "        weather_map_df.loc[row,\"Conds_Description\"] = str(observation_conds_description)\n",
    "        weather_map_df.loc[row,\"Hail\"] = float(observation_hail)\n",
    "\n",
    "    #get destination conditions - same process as above\n",
    "    STATE = weather_map_df.iloc[row][\"DEST_STATE_ABR\"]\n",
    "    CITY = weather_map_df.iloc[row][\"DEST\"]  \n",
    "             \n",
    "    dest_conditions = get_conditions(STARTDATE2.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "    if (dest_conditions != False):\n",
    "        for i in range(len(dest_conditions['history']['observations'])):\n",
    "            dateInfo = dest_conditions['history']['observations'][i]['date']\n",
    "            date_holder = dateInfo['mon']+\"/\"+dateInfo['mday']+\"/\"+dateInfo['year']+\" \"+dateInfo['hour']+dateInfo['min']\n",
    "            pattern = '%m/%d/%Y %H%M'\n",
    "            dest_date_wu.append(date_holder)\n",
    "            epoch = int(time.mktime(time.strptime(date_holder, pattern)))\n",
    "\n",
    "            dest_humidity_wu.append(dest_conditions['history']['observations'][i]['hum'])\n",
    "            dest_temp_wu.append(dest_conditions['history']['observations'][i]['tempi'])\n",
    "            dest_pressure_wu.append(dest_conditions['history']['observations'][i]['pressurei'])\n",
    "            dest_precip_wu.append(dest_conditions['history']['observations'][i]['precipi'])\n",
    "            dest_wind_speed_wu.append(dest_conditions['history']['observations'][i]['wspdi'])\n",
    "            dest_dewpt_wu.append(dest_conditions['history']['observations'][i]['dewpti'])\n",
    "            dest_wind_gust_wu.append(dest_conditions['history']['observations'][i]['wgusti'])\n",
    "            dest_wind_dir_wu.append(dest_conditions['history']['observations'][i]['wdird'])\n",
    "            dest_vis_wu.append(dest_conditions['history']['observations'][i]['visi'])\n",
    "            dest_wind_chill_wu.append(dest_conditions['history']['observations'][i]['windchilli'])\n",
    "            dest_heat_index_wu.append(dest_conditions['history']['observations'][i]['heatindexi'])\n",
    "            dest_conds_wu.append(dest_conditions['history']['observations'][i]['conds'])\n",
    "            dest_fog_wu.append(dest_conditions['history']['observations'][i]['fog'])\n",
    "            dest_rain_wu.append(dest_conditions['history']['observations'][i]['rain'])\n",
    "            dest_snow_wu.append(dest_conditions['history']['observations'][i]['snow'])\n",
    "            dest_hail_wu.append(dest_conditions['history']['observations'][i]['hail'])\n",
    "            dest_thunder_wu.append(dest_conditions['history']['observations'][i]['thunder'])\n",
    "            dest_tornado_wu.append(dest_conditions['history']['observations'][i]['tornado'])\n",
    "\n",
    "        dest_obs_df = pd.DataFrame({\n",
    "            \"Date\":dest_date_wu,\n",
    "            \"Temp\":dest_temp_wu,\n",
    "            \"Pressure\":dest_pressure_wu,\n",
    "            \"Precipitation\":dest_precip_wu,\n",
    "            \"Wind_Gust\":dest_wind_gust_wu,\n",
    "            \"Wind\":dest_wind_speed_wu,\n",
    "            \"Visibility\":dest_vis_wu,\n",
    "            \"Conds_Description\":dest_conds_wu,\n",
    "            \"Fog\":dest_fog_wu,\n",
    "            \"Rain\":dest_rain_wu,\n",
    "            \"Snow\":dest_snow_wu,\n",
    "            \"Hail\":dest_hail_wu,\n",
    "            \"Thunder\":dest_thunder_wu,\n",
    "            \"Tornado\":dest_tornado_wu\n",
    "        })\n",
    "\n",
    "        military_time = int(weather_map_df.iloc[row][\"CRS_ARR_TIME\"])\n",
    "        if military_time < 1000:\n",
    "            time_str = \"0\" + str(military_time)\n",
    "        else:\n",
    "            time_str = str(military_time)\n",
    "\n",
    "        closest_time = rec_time\n",
    "        min_diff = 99999999999\n",
    "\n",
    "        converted_timestamps = []\n",
    "        for raw_time in dest_date_wu:\n",
    "            converted_time = datetime.strptime(raw_time, '%m/%d/%Y %H%M')\n",
    "            converted_timestamps.append(converted_time)\n",
    "            diff = rec_time - converted_time\n",
    "            if diff.seconds < min_diff:\n",
    "                min_diff = diff.seconds\n",
    "                closest_time = converted_time\n",
    "\n",
    "        closest = closest_time.strftime(\"%m/%d/%Y %H%M\")        \n",
    "\n",
    "        observation = dest_obs_df.loc[dest_obs_df[\"Date\"]==closest,:]\n",
    "        observation_fog = observation[\"Fog\"]\n",
    "        observation_pressure = observation[\"Pressure\"]\n",
    "        observation_snow = observation[\"Snow\"]\n",
    "        observation_temp = observation[\"Temp\"]\n",
    "        observation_thunder = observation[\"Thunder\"]\n",
    "        observation_wind = observation[\"Wind\"]\n",
    "        observation_wind_gust = observation[\"Wind_Gust\"]\n",
    "        observation_rain = observation[\"Rain\"]\n",
    "        observation_tornado = observation[\"Tornado\"]\n",
    "        observation_visibility = observation[\"Visibility\"]\n",
    "        observation_conds_description = observation[\"Conds_Description\"]\n",
    "        observation_precipitation = observation[\"Precipitation\"]\n",
    "        observation_hail = observation[\"Hail\"]\n",
    "\n",
    "        weather_map_df.loc[row,\"Dest_Fog\"] = float(observation_fog)\n",
    "        weather_map_df.loc[row,\"Dest_Pressure\"] = float(observation_pressure)\n",
    "        weather_map_df.loc[row,\"Dest_Snow\"] = float(observation_snow)\n",
    "        weather_map_df.loc[row,\"Dest_Temp\"] = float(observation_temp)\n",
    "        weather_map_df.loc[row,\"Dest_Thunder\"] = float(observation_thunder)\n",
    "        weather_map_df.loc[row,\"Dest_Wind\"] = float(observation_wind)\n",
    "        weather_map_df.loc[row,\"Dest_Wind_Gust\"] = float(observation_wind_gust)\n",
    "        weather_map_df.loc[row,\"Dest_Rain\"] = float(observation_rain)\n",
    "        weather_map_df.loc[row,\"Dest_Tornado\"] = float(observation_tornado)\n",
    "        weather_map_df.loc[row,\"Dest_Visibility\"] = float(observation_visibility)\n",
    "        weather_map_df.loc[row,\"Dest_Conds_Description\"] = str(observation_conds_description)\n",
    "        weather_map_df.loc[row,\"Dest_Hail\"] = float(observation_hail)\n",
    "        \n",
    "weather_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save file to csv - start next block of code based on most records received before limit reached\n",
    "weather_map_df.to_csv(\"book2.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_map_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PETE'S CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in CSV and elminate rows where measurements do not  make sense\n",
    "weather_map_df = pd.read_csv(\"Book2.csv\")\n",
    "weather_map_df = weather_map_df[weather_map_df.Temp != 0]\n",
    "weather_map_df = weather_map_df[weather_map_df.Pressure != 0]\n",
    "weather_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create new df with only oberservations to be analyzed\n",
    "plots = pd.DataFrame(weather_map_df.loc[:,[\"WEATHER_DELAY\",\"Wind\",\"Pressure\",\"Fog\",\"Visibility\",\"Temp\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create scatterplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.scatter(plots[\"Wind\"],plots[\"WEATHER_DELAY\"],\n",
    "            alpha = 0.75,\n",
    "            edgecolor = \"black\")\n",
    "plt.title(\"Flight Delay Length vs Severity of Wind\")\n",
    "plt.xlabel(\"Wind Speed [mph]\")\n",
    "plt.ylabel(\"Length of Delay [minutes]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10,7))\n",
    "plt.scatter(plots[\"Pressure\"],plots[\"WEATHER_DELAY\"],\n",
    "            alpha = 0.75,\n",
    "            edgecolor = \"black\")\n",
    "plt.title(\"Flight Delay Length vs Pressure\")\n",
    "plt.xlabel(\"Pressure [Inches of Mercury]\")\n",
    "plt.ylabel(\"Length of Delay [minutes]\")\n",
    "plt.xlim(29.5,30.5)\n",
    "pressure_floats = plots[\"Pressure\"].astype(float).sort_values()\n",
    "delay_floats = plots[\"WEATHER_DELAY\"].astype(float)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(plots[\"Visibility\"],plots[\"WEATHER_DELAY\"],\n",
    "            alpha = 0.75,\n",
    "            edgecolor = \"black\")\n",
    "plt.title(\"Flight Delay Length vs Visibility\")\n",
    "plt.xlabel(\"Visibility [miles]\")\n",
    "plt.ylabel(\"Length of Delay [minutes]\")\n",
    "#plt.plot(x, m*x + b, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(plots[\"Temp\"],plots[\"WEATHER_DELAY\"],\n",
    "            alpha = 0.75,\n",
    "            edgecolor = \"black\")\n",
    "plt.title(\"Flight Delay Length vs Temperature\")\n",
    "plt.xlabel(\"Temperature [F]\")\n",
    "plt.ylabel(\"Length of Delay [minutes]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import scipy\n",
    "#regr = linear_model.LinearRegression()\n",
    "#regr.fit(pressure_floats, delay_floats)\n",
    "from pandas.plotting import scatter_matrix\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = pd.DataFrame(weather_map_df.loc[:,[\"Wind\",\"Pressure\",\"Visibility\",\"Temp\",\"Delay Bins\"]])\n",
    "bins = [0, 15, 30, 45, 60, 120, 180,360,100000]\n",
    "labels = [\"< 15\",\"15< x <30\",\"30,45\",\"45,60\",\"60,120\",\"120,180\",\"180,360\",\"> 360\"]\n",
    "weather_map_df[\"Delay Bins\"] = pd.cut(weather_map_df[\"WEATHER_DELAY\"], bins=bins, labels = labels)\n",
    "\n",
    "ml = pd.DataFrame(weather_map_df.loc[:,[\"Wind\",\"Pressure\",\"Visibility\",\"Temp\",\"Delay Bins\"]])\n",
    "ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "scatter_matrix(ml,figsize = (12,8))\n",
    "ax1 = plt.subplot(442)\n",
    "ax1.set_xlim([29.5,30.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(ml, hue = \"Delay Bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = ml.values\n",
    "x = array[:,0:4]\n",
    "y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = \"accuracy\"\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x, y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = ml.values\n",
    "\n",
    "x = array[:,0:4]\n",
    "\n",
    "y = array[:,4]\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = \"accuracy\"\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x, y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    perc = round(cv_results.mean()*100,2)  ## taking the mean becuse it is passing ten times\n",
    "    std = round(cv_results.std(),2)\n",
    "    msg = f\"{name} has an accuracy percentage of {perc}% and a standard deviation of {std}\"\n",
    "    #msg = \"%s: %f (%f)\" % (name, round(cv_results.mean()*100, cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "SVM, CART and KNN are our top two finishers:\n",
    "SVM is \"Support Vector Machines\" - attempts to create a hyperplane separating classifications, and assigns test data a classification based on where in relation to the hyperplane that point lies\n",
    "CART is \"Decision Tree\" - attempts to create a series of hierachichal decisions to lead to a classification\n",
    "KNN is \"k-Nearest Neighbot\" - attemps to classify test data by analyzing nearest known data \n",
    "Analysis\n",
    "These models are really bad...\n",
    "Consistently less than 30% accuracy does not allow us to confidently classify delay ranges based on weather input at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "#fig.suptitle('Algorithm Comparison')\n",
    "plt.title(\"Algorithm Comparison with 8 Bins\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.xlabel(\"Algorithm\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.y_ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "# Make predictions on validation dataset\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "lr = LogisticRegression()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "cart = DecisionTreeClassifier()\n",
    "nb = GaussianNB()\n",
    "tests = [knn, svm, lr, lda, cart, nb]\n",
    "for test in tests:\n",
    "    test.fit(x_train, y_train)\n",
    "    predictions = test.predict(x_valid)\n",
    "    print(\"Accuracy of \" + str(test) + \": \" + str((round(accuracy_score(y_valid, predictions)*100,2))) + \"%\")\n",
    "    print(\"=============\")\n",
    "    print(\"CONFUSION MATRIX\")\n",
    "    print(confusion_matrix(y_valid, predictions))\n",
    "    #print(classification_report(y_valid, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAYS OF WEEK DELAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_delays_df = weather_df.loc[(weather_df[\"DEP_DELAY\"]>0),:]\n",
    "all_delays_df.reset_index(inplace=True)\n",
    "all_delays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_delay_df = pd.DataFrame(all_delays_df.loc[:,[\"FL_DATE\",\"DAY_OF_WEEK\",\"UNIQUE_CARRIER\",\n",
    "                                                \"ORIGIN\",\"DEP_TIME\",\"DEP_TIME_BLK\",\"DEP_DELAY\"]])\n",
    "weekday_delay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_weekday = weekday_delay_df.groupby([\"DAY_OF_WEEK\"])\n",
    "grouped_weekday_delay = pd.DataFrame(grouped_weekday[\"DEP_DELAY\"].mean())\n",
    "grouped_weekday_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_weekday_delay.plot(kind='bar', title='Average Departure Delay by Hub Flight Type', figsize=(20,10))\n",
    "plt.savefig(\"delaybyday.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_timeblk = weekday_delay_df.groupby([\"DEP_TIME_BLK\"])\n",
    "timeblk = pd.DataFrame(grouped_timeblk[\"DEP_DELAY\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeblk.plot(kind='bar', title='Average Delay by Time of Day', figsize=(20,10))\n",
    "plt.savefig(\"delaybytimeblock.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference to CSV file\n",
    "csv_path_hub = \"cy16-commercial-service-enplanements.csv\"\n",
    "\n",
    "# Import the CSV into a pandas DataFrame\n",
    "hub_df = pd.read_csv(csv_path_hub, low_memory=False)\n",
    "hub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hub_df = pd.DataFrame(weather_df.loc[:,[\"FL_DATE\",\"CARRIER\",\"ORIGIN\",\"HUB_SIZE\",\"ORIGIN_STATE_ABR\",\"DEST\",\"DEST_HUB_SIZE\",\"DEST_STATE_ABR\",\"DEP_TIME\",\"WEATHER_DELAY\",\"CARRIER_DELAY\",\"NAS_DELAY\",\"SECURITY_DELAY\",\"CANCELLATION_CODE\"]])\n",
    "weather_hub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_weather_delays_df = weather_hub_df.loc[(((weather_hub_df[\"WEATHER_DELAY\"] > 0) | (weather_hub_df[\"CARRIER_DELAY\"] > 0) | (weather_hub_df[\"NAS_DELAY\"] > 0) | (weather_hub_df[\"SECURITY_DELAY\"] > 0)) & ((weather_hub_df[\"HUB_SIZE\"] != \"N\") & (weather_hub_df[\"HUB_SIZE\"] != \"None\")) & ((weather_hub_df[\"DEST_HUB_SIZE\"] != \"N\") & (weather_hub_df[\"DEST_HUB_SIZE\"] != \"None\")))]\n",
    "hub_weather_delays_df.reset_index(inplace=True)\n",
    "hub_weather_delays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_weather_delays_df[\"HUB_FLIGHT\"] = hub_weather_delays_df[\"HUB_SIZE\"] + hub_weather_delays_df[\"DEST_HUB_SIZE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's group by state now and sum the number of delays.\n",
    "by_hub_size = hub_weather_delays_df.groupby('HUB_FLIGHT')\n",
    "weather_delay_average = by_hub_size[\"WEATHER_DELAY\"].mean()\n",
    "weather_delay_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_delay_average = by_hub_size[\"CARRIER_DELAY\"].mean()\n",
    "carrier_delay_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_delay_average = by_hub_size[\"NAS_DELAY\"].mean()\n",
    "nas_delay_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_delay_average = by_hub_size[\"SECURITY_DELAY\"].mean()\n",
    "security_delay_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df = pd.DataFrame([weather_delay_average]).T\n",
    "print(delay_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df = pd.DataFrame([weather_delay_average, carrier_delay_average, nas_delay_average]).T\n",
    "delay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df.plot(kind='bar', title='Average Delay by Hub Flight Type', figsize=(20,10))\n",
    "plt.savefig(\"delaybyhub.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
